{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1fc107-77e9-48d8-8054-ca376a8d7317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T03:57:26.504495Z",
     "iopub.status.busy": "2024-07-14T03:57:26.502860Z",
     "iopub.status.idle": "2024-07-14T03:57:36.908728Z",
     "shell.execute_reply": "2024-07-14T03:57:36.906437Z",
     "shell.execute_reply.started": "2024-07-14T03:57:26.504437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'translation-agent'...\n",
      "remote: Enumerating objects: 226, done.\u001b[K\n",
      "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
      "remote: Total 226 (delta 48), reused 41 (delta 31), pack-reused 151\u001b[K\n",
      "Receiving objects: 100% (226/226), 26.82 MiB | 4.63 MiB/s, done.\n",
      "Resolving deltas: 100% (87/87), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone git@github.com:andrewyng/translation-agent.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71021bb4-2590-4b74-9f0c-5de4b01f9fe7",
   "metadata": {},
   "source": [
    "## Andrew NG `Agentic Reasoning`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee2efa9-d557-4e7e-82d0-35d4c08fdab4",
   "metadata": {},
   "source": [
    "> GPT-4 + Agent = GPT-5 （挺标题党的）\n",
    "\n",
    "- prompt engineering（LLM-based agents）\n",
    "    - modern：LLMs 重写一切；\n",
    "    - effective\n",
    "    - for engineer & research\n",
    "- 今年4月份的 Agentic 的演讲，6月份的 translation-agent（截止到目前4k的star） 的一个具体实践；\n",
    "    - https://github.com/andrewyng/translation-agent\n",
    "        - https://github.com/andrewyng/translation-agent/blob/main/src/translation_agent/utils.py\n",
    "- workflow\n",
    "    - 复杂任务的分解和抽象；\n",
    "        - step by steps 的完成一些相对较为简单的子任务要比 LLM 直出的完成一个复杂任务，更为简单而有效；\n",
    "    - 现实世界人类经验的镜像；\n",
    "- Agentic Reasoning design patterns\n",
    "    - **Reflection**\n",
    "    - Tool use\n",
    "    - Planning\n",
    "    - Multi-Agent Collaboration\n",
    "- 推荐下[《大模型应用开发 动手做AI Agent GPT大语言模型应用》](https://www.bilibili.com/opus/935785456083140628?spm_id_from=333.999.0.0)\n",
    "    - 面向开发者\n",
    "    - 系统而全面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998c989-d201-4046-9f89-6778342d7805",
   "metadata": {},
   "source": [
    "## prompt & workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9330bb7e-21b0-4bdb-b358-31ad66f4ba2d",
   "metadata": {},
   "source": [
    "\n",
    "- prompt: 具体的业务要求；\n",
    "- (agentic) workflow：对应着一种分解和抽象；\n",
    "\n",
    "```\n",
    "def translate(\n",
    "    source_lang,\n",
    "    target_lang,\n",
    "    source_text,\n",
    "    country,\n",
    "    max_tokens=MAX_TOKENS_PER_CHUNK,\n",
    "):\n",
    "    if ...\n",
    "        final_translation = one_chunk_translate_text(\n",
    "                source_lang, target_lang, source_text, country\n",
    "            )\n",
    "    \n",
    "        return final_translation\n",
    "    else:\n",
    "        source_text_chunks = text_splitter.split_text(source_text)\n",
    "\n",
    "        translation_2_chunks = multichunk_translation(\n",
    "            source_lang, target_lang, source_text_chunks, country\n",
    "        )\n",
    "\n",
    "        return \"\".join(translation_2_chunks)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d5dc9-9ebc-45cb-98c9-4e006c0103f9",
   "metadata": {},
   "source": [
    "### onechunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36bc83-5eb0-4f8f-ad19-dc6afec87113",
   "metadata": {},
   "source": [
    "\n",
    "- `one_chunk_initial_translation`\n",
    "- `one_chunk_reflect_on_translation`\n",
    "- `one_chunk_translate_text`\n",
    "\n",
    "    ```\n",
    "    def one_chunk_translate_text(\n",
    "        source_lang: str, target_lang: str, source_text: str, country: str = \"\"\n",
    "    ) -> str:\n",
    "        translation_1 = one_chunk_initial_translation(\n",
    "            source_lang, target_lang, source_text\n",
    "        )\n",
    "        \n",
    "        reflection = one_chunk_reflect_on_translation(\n",
    "            source_lang, target_lang, source_text, translation_1, country\n",
    "        )\n",
    "        translation_2 = one_chunk_improve_translation(\n",
    "            source_lang, target_lang, source_text, translation_1, reflection\n",
    "        )\n",
    "        return translation_2\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193287a-5cdc-4d40-9421-4dbcd684a660",
   "metadata": {},
   "source": [
    "### multichunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2aeb86-8f8e-47f1-acb1-0c2de865b219",
   "metadata": {},
   "source": [
    "```\n",
    "def multichunk_translation(\n",
    "    source_lang, target_lang, source_text_chunks, country: str = \"\"\n",
    "):\n",
    "        translation_1_chunks = multichunk_initial_translation(\n",
    "            source_lang, target_lang, source_text_chunks\n",
    "        )\n",
    "    \n",
    "        reflection_chunks = multichunk_reflect_on_translation(\n",
    "            source_lang,\n",
    "            target_lang,\n",
    "            source_text_chunks,\n",
    "            translation_1_chunks,\n",
    "            country,\n",
    "        )\n",
    "    \n",
    "        translation_2_chunks = multichunk_improve_translation(\n",
    "            source_lang,\n",
    "            target_lang,\n",
    "            source_text_chunks,\n",
    "            translation_1_chunks,\n",
    "            reflection_chunks,\n",
    "        )\n",
    "    \n",
    "        return translation_2_chunks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbfb901-8743-4534-9e36-bf9bd155aaa8",
   "metadata": {},
   "source": [
    "- `split chunks；`\n",
    "- `from langchain_text_splitters import RecursiveCharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c056b7da-875c-4e2b-a21e-898c6647fb60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T11:48:24.074267Z",
     "iopub.status.busy": "2024-07-14T11:48:24.072985Z",
     "iopub.status.idle": "2024-07-14T11:48:24.085227Z",
     "shell.execute_reply": "2024-07-14T11:48:24.083940Z",
     "shell.execute_reply.started": "2024-07-14T11:48:24.074212Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_chunk_size(token_count: int, token_limit: int) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the chunk size based on the token count and token limit.\n",
    "\n",
    "    Args:\n",
    "        token_count (int): The total number of tokens.\n",
    "        token_limit (int): The maximum number of tokens allowed per chunk.\n",
    "\n",
    "    Returns:\n",
    "        int: The calculated chunk size.\n",
    "\n",
    "    Description:\n",
    "        This function calculates the chunk size based on the given token count and token limit.\n",
    "        If the token count is less than or equal to the token limit, the function returns the token count as the chunk size.\n",
    "        Otherwise, it calculates the number of chunks needed to accommodate all the tokens within the token limit.\n",
    "        The chunk size is determined by dividing the token limit by the number of chunks.\n",
    "        If there are remaining tokens after dividing the token count by the token limit,\n",
    "        the chunk size is adjusted by adding the remaining tokens divided by the number of chunks.\n",
    "\n",
    "    Example:\n",
    "        >>> calculate_chunk_size(1000, 500)\n",
    "        500\n",
    "        >>> calculate_chunk_size(1530, 500)\n",
    "        389\n",
    "        >>> calculate_chunk_size(2242, 500)\n",
    "        496\n",
    "    \"\"\"\n",
    "\n",
    "    if token_count <= token_limit:\n",
    "        return token_count\n",
    "\n",
    "    num_chunks = (token_count + token_limit - 1) // token_limit\n",
    "    chunk_size = token_count // num_chunks\n",
    "\n",
    "    remaining_tokens = token_count % token_limit\n",
    "    if remaining_tokens > 0:\n",
    "        chunk_size += remaining_tokens // num_chunks\n",
    "\n",
    "    return chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a01f7f83-90a9-4ae9-9cb2-be15e6a802a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T11:55:56.468212Z",
     "iopub.status.busy": "2024-07-14T11:55:56.467646Z",
     "iopub.status.idle": "2024-07-14T11:55:56.477092Z",
     "shell.execute_reply": "2024-07-14T11:55:56.475730Z",
     "shell.execute_reply.started": "2024-07-14T11:55:56.468168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向上取整\n",
    "(1530 + 500-1) // 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3554da-c693-4c22-a226-b0aff176c208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:11:04.231853Z",
     "iopub.status.busy": "2024-07-14T05:11:04.231261Z",
     "iopub.status.idle": "2024-07-14T05:11:04.241210Z",
     "shell.execute_reply": "2024-07-14T05:11:04.239254Z",
     "shell.execute_reply.started": "2024-07-14T05:11:04.231808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1530 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0eccfa-8139-4a37-885f-efe19b8acf43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:11:13.608088Z",
     "iopub.status.busy": "2024-07-14T05:11:13.607472Z",
     "iopub.status.idle": "2024-07-14T05:11:13.614467Z",
     "shell.execute_reply": "2024-07-14T05:11:13.613609Z",
     "shell.execute_reply.started": "2024-07-14T05:11:13.608043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1530 % 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85552e1d-d298-4d58-8ce5-8359386722ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T05:11:38.617749Z",
     "iopub.status.busy": "2024-07-14T05:11:38.616268Z",
     "iopub.status.idle": "2024-07-14T05:11:38.626539Z",
     "shell.execute_reply": "2024-07-14T05:11:38.625255Z",
     "shell.execute_reply.started": "2024-07-14T05:11:38.617704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "382 + 30//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a09a9da-5c16-4247-9732-994c3b862c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T12:49:38.464030Z",
     "iopub.status.busy": "2024-07-14T12:49:38.463726Z",
     "iopub.status.idle": "2024-07-14T12:49:38.907626Z",
     "shell.execute_reply": "2024-07-14T12:49:38.906800Z",
     "shell.execute_reply.started": "2024-07-14T12:49:38.464016Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import translate\n",
    "\n",
    "source_lang = \"English\"\n",
    "target_lang = \"Chinese\"\n",
    "\n",
    "source_text = '''The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
    "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation [35, 2, 5]. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures [38, 24, 15].\n",
    "Recurrent models typically factor computation along the symbol positions of the input and output\n",
    "sequences  Aligning the positions to steps in computation time, they generate a sequence of hidden states $h_t$, as a function of the previous hidden state $h_{t−1}$ and the input for position $t$. This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples. Recent work has achieved significant improvements in computational efficiency through factorization tricks [21] and conditional computation [32], while also improving model performance in case of the latter. The fundamental\n",
    "constraint of sequential computation, however, remains.\n",
    "Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms are used in conjunction with a recurrent network.\n",
    "In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs. \n",
    "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n",
    "[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\n",
    "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
    "the number of operations required to relate signals from two arbitrary input or output positions grows\n",
    "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
    "it more difficult to learn dependencies between distant positions [12]. In the Transformer this is\n",
    "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
    "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
    "described in section 3.2.\n",
    "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
    "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
    "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
    "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
    "End-to-end memory networks are based on a recurrent attention mechanism instead of sequencealigned recurrence and have been shown to perform well on simple-language question answering and\n",
    "language modeling tasks [34].\n",
    "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
    "entirely on self-attention to compute representations of its input and output without using sequencealigned RNNs or convolution. In the following sections, we will describe the Transformer, motivate self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
    "\n",
    "In this work, we presented the Transformer, the first sequence transduction model based entirely on\n",
    "attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\n",
    "multi-headed self-attention.\n",
    "For translation tasks, the Transformer can be trained significantly faster than architectures based\n",
    "on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\n",
    "English-to-French translation tasks, we achieve a new state of the art. In the former task our best\n",
    "model outperforms even all previously reported ensembles.\n",
    "We are excited about the future of attention-based models and plan to apply them to other tasks. We\n",
    "plan to extend the Transformer to problems involving input and output modalities other than text and\n",
    "to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\n",
    "such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
    "The code we used to train and evaluate our models is available at https://github.com/\n",
    "tensorflow/tensor2tensor.\n",
    "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\n",
    "comments, corrections and inspiration.\n",
    "'''\n",
    "\n",
    "country = 'China'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafcb02-8115-495d-8688-299fb2203135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T12:49:41.845493Z",
     "iopub.status.busy": "2024-07-14T12:49:41.845234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_tokens_in_text: 1166\n",
      "ic| 'Translating text as multiple chunks'\n",
      "ic| token_size: 666\n"
     ]
    }
   ],
   "source": [
    "translate(source_lang, target_lang, source_text, country)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
